# -*- coding: utf-8 -*-
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # å¯ç”¨GPUåŠ é€Ÿ

import akshare as ak
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import tensorflow as tf
import matplotlib.font_manager as fm
import datetime
import time
import psutil
from concurrent.futures import ThreadPoolExecutor
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping

# ========== ç³»ç»Ÿåˆå§‹åŒ– ==========
# 1. æŒ‡å®šä¸­æ–‡å­—ä½“è·¯å¾„
font_path = "./fonts/simhei.ttf"  # ç¡®ä¿å­—ä½“æ–‡ä»¶å­˜åœ¨

# 2. åŠ¨æ€æ·»åŠ å­—ä½“
try:
    font_prop = fm.FontProperties(fname=font_path)
    fm.fontManager.addfont(font_path)
    plt.rcParams["font.family"] = font_prop.get_name()
    plt.rcParams["axes.unicode_minus"] = False
except Exception as e:
    st.warning(f"å­—ä½“åŠ è½½å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")

# 3. GPUå†…å­˜ä¼˜åŒ–é…ç½®
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        st.error(f"GPUé…ç½®é”™è¯¯: {str(e)}")

# 4. è®¾ç½®Streamlité¡µé¢
st.set_page_config(page_title="æ²ªæ·±300é¢„æµ‹ç³»ç»Ÿ", layout="wide")
st.title("ğŸ“ˆ æ²ªæ·±300æŒ‡æ•°é¢„æµ‹å¯è§†åŒ–ç³»ç»Ÿ")

# ========== å‚æ•°è®¾ç½® ==========
with st.sidebar:
    st.header("æ¨¡å‹å‚æ•°")
    epochs = st.slider("è®­ç»ƒè½®æ¬¡(epochs)", 50, 200, 100)
    timesteps = st.slider("æ—¶é—´æ­¥é•¿(timesteps)", 30, 90, 60)
    batch_size = st.slider("æ‰¹å¤§å°(batch_size)", 16, 64, 32)
    
    st.divider()
    st.info(f"å½“å‰æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    if st.button("é‡æ–°è®­ç»ƒæ¨¡å‹"):
        keys = ['model', 'predictions', 'scaled_data', 'X', 'y']
        for key in keys:
            if key in st.session_state:
                del st.session_state[key]
        st.experimental_rerun()

# ========== æ•°æ®è·å–ä¸é¢„å¤„ç† ==========
@st.cache_data(ttl=3600, show_spinner="åŠ è½½å†å²æ•°æ®...")
def load_data():
    try:
        hs300 = ak.stock_zh_index_daily(symbol="sh000300")
        hs300['date'] = pd.to_datetime(hs300['date'])
        hs300.set_index('date', inplace=True)
        # æ•°æ®æ¸…æ´—ï¼šå¤„ç†å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼
        hs300 = hs300[hs300['close'] > 0].ffill().bfill()
        return hs300[hs300.index >= pd.to_datetime('2020-01-01')].copy()
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        st.stop()

try:
    with st.spinner('æ­£åœ¨åŠ è½½æ²ªæ·±300å†å²æ•°æ®...'):
        hs300 = load_data()
        last_date = hs300.index[-1].date()
        next_trading_day = last_date + pd.offsets.BDay(1)
    st.success(f"æ•°æ®åŠ è½½å®Œæˆ! æœ€åæ•°æ®æ—¥æœŸ: {last_date.strftime('%Y-%m-%d')}")
except Exception as e:
    st.error(f"æ•°æ®åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    st.stop()

# æ˜¾ç¤ºæ•°æ®æ‘˜è¦
st.subheader("å†å²æ•°æ®æ¦‚è§ˆ")
st.dataframe(hs300.tail().style.format({'close': '{:.2f}', 'volume': '{:,.0f}'}), height=150)
st.line_chart(hs300[['close']], use_container_width=True)

# æ•°æ®é¢„å¤„ç†ï¼ˆç¼“å­˜é¢„å¤„ç†ç»“æœï¼‰
@st.cache_data
def preprocess_data(_hs300):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(_hs300[['close']].values)
    
    # æ•°æ®éªŒè¯
    if np.isnan(scaled_data).any():
        st.error("æ•°æ®åŒ…å«NaNå€¼ï¼")
        st.stop()
    return scaler, scaled_data

scaler, scaled_data = preprocess_data(hs300)

# åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®é›†
@st.cache_data
def create_dataset(_data, _timesteps):
    X, y = [], []
    for i in range(_timesteps, len(_data)):
        X.append(_data[i - _timesteps:i, 0])
        y.append(_data[i, 0])
    return np.array(X), np.array(y)

# ========== æ¨¡å‹æ„å»ºä¸è®­ç»ƒ ==========
def build_model(_timesteps):
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=(_timesteps, 1)),
        LSTM(32),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    return model

def train_model(_model, _X, _y, _epochs, _batch_size):
    # åŠ¨æ€è°ƒæ•´batch_sizeé¿å…å†…å­˜æº¢å‡º
    adjusted_batch = min(_batch_size, len(_X)//10)
    
    # æ·»åŠ æ—©åœæœºåˆ¶
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    
    history = _model.fit(
        _X, _y,
        epochs=_epochs,
        batch_size=adjusted_batch,
        validation_split=0.2,
        verbose=0,
        callbacks=[early_stop]
    )
    return history

# ä¸»è®­ç»ƒæµç¨‹
def main_training():
    # ç›‘æ§å†…å­˜ä½¿ç”¨
    mem = psutil.virtual_memory()
    st.info(f"å½“å‰å†…å­˜ä½¿ç”¨: {mem.used/(1024**3):.2f}GB / {mem.total/(1024**3):.2f}GB")
    if mem.available < 1 * 1024**3:  # <1GBæ—¶æŠ¥è­¦
        st.error("å†…å­˜ä¸è¶³! è¯·å‡å°‘æ—¶é—´æ­¥é•¿æˆ–æ‰¹å¤§å°")
        st.stop()
    
    # åˆ›å»ºæ•°æ®é›†
    if 'X' not in st.session_state or 'y' not in st.session_state:
        X, y = create_dataset(scaled_data, timesteps)
        st.session_state.X = X
        st.session_state.y = y
    else:
        X = st.session_state.X
        y = st.session_state.y
        
    # éªŒè¯æ•°æ®å½¢çŠ¶
    if len(X.shape) != 3:
        X = X.reshape(X.shape[0], X.shape[1], 1)
    st.write(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {X.shape} | ç›®æ ‡æ•°æ®å½¢çŠ¶: {y.shape}")
    
    # æ„å»ºæ¨¡å‹
    model = build_model(timesteps)
    
    # è®­ç»ƒæ¨¡å‹
    st.subheader("æ¨¡å‹è®­ç»ƒè¿‡ç¨‹")
    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.info("æ¨¡å‹è®­ç»ƒä¸­ï¼Œè¯·ç¨å€™...")
    
    start_time = time.time()
    try:
        history = train_model(model, X, y, epochs, batch_size)
    except Exception as e:
        import traceback
        st.error(f"è®­ç»ƒå¤±è´¥: {str(e)}")
        st.code(traceback.format_exc())
        st.stop()
    
    training_time = time.time() - start_time
    progress_bar.progress(100)
    status_text.success(f"æ¨¡å‹è®­ç»ƒå®Œæˆ! è€—æ—¶: {training_time:.2f}ç§’")
    st.session_state['model'] = model
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
    ax.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
    ax.set_title('æ¨¡å‹æŸå¤±å˜åŒ–')
    ax.set_ylabel('æŸå¤±')
    ax.set_xlabel('è®­ç»ƒè½®æ¬¡')
    ax.legend()
    st.pyplot(fig)
    
    return model

# æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
if 'model' not in st.session_state:
    model = main_training()
else:
    model = st.session_state['model']
    st.success("ä½¿ç”¨ç¼“å­˜çš„è®­ç»ƒæ¨¡å‹")

# ========== é¢„æµ‹ä¸å¯è§†åŒ– ==========
def predict_tomorrow():
    last_60_days = scaled_data[-timesteps:]
    last_60_days = last_60_days.reshape(1, timesteps, 1)
    
    with tf.device('/GPU:0'):
        pred_scaled = model.predict(last_60_days, verbose=0)
    
    return scaler.inverse_transform(pred_scaled)[0][0]

tomorrow_pred = predict_tomorrow()

# è®¡ç®—å†å²å‡†ç¡®æ€§
if 'predictions' not in st.session_state:
    predictions = []
    actuals = hs300.iloc[timesteps:]['close'].values
    
    def predict_point(i):
        input_data = scaled_data[i - timesteps:i].reshape(1, timesteps, 1)
        pred = model.predict(input_data, verbose=0)
        return scaler.inverse_transform(pred)[0][0]
    
    # å¹¶è¡Œé¢„æµ‹
    with ThreadPoolExecutor() as executor:
        futures = [executor.submit(predict_point, i) 
                  for i in range(timesteps, len(scaled_data))]
        predictions = [f.result() for f in futures]
    
    st.session_state['predictions'] = predictions
    st.session_state['actuals'] = actuals
else:
    predictions = st.session_state['predictions']
    actuals = st.session_state['actuals']

errors = np.abs(predictions - actuals)
accuracy = 100 * (1 - errors / actuals)

# æ˜¾ç¤ºç»“æœ
st.subheader("é¢„æµ‹ç»“æœ")
pred_date = next_trading_day.strftime("%Y-%m-%d")
change = tomorrow_pred - hs300['close'].iloc[-1]

st.metric(label=f"{pred_date} é¢„æµ‹æ”¶ç›˜ä»·",
          value=f"{tomorrow_pred:.2f}",
          delta=f"{change:.2f}",
          delta_color="normal")

# å¯è§†åŒ–é¢„æµ‹
st.subheader("è¿‘æœŸè¡¨ç°ä¸é¢„æµ‹")
fig, ax = plt.subplots(figsize=(12, 6))

# å†å²æ•°æ®
ax.plot(hs300.index[-60:], hs300['close'].iloc[-60:], 'b-', label='å†å²æ•°æ®')

# é¢„æµ‹ç‚¹
prediction_point = last_date + pd.Timedelta(days=1)
ax.plot(prediction_point, tomorrow_pred, 'ro', markersize=8, label='é¢„æµ‹å€¼')

# å†å²é¢„æµ‹ç‚¹
accuracy_df = pd.DataFrame({
    'date': hs300.index[timesteps:][-30:],
    'predicted': predictions[-30:]
})
ax.plot(accuracy_df['date'], accuracy_df['predicted'], 'g--', alpha=0.7, label='å†å²é¢„æµ‹')

ax.set_title('æ²ªæ·±300æŒ‡æ•°é¢„æµ‹')
ax.set_xlabel('æ—¥æœŸ')
ax.set_ylabel('æ”¶ç›˜ä»·')
ax.legend()
plt.xticks(rotation=45)
plt.tight_layout()
st.pyplot(fig)

# æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
st.subheader("æ¨¡å‹æ€§èƒ½è¯„ä¼°")
col1, col2, col3 = st.columns(3)
col1.metric("å¹³å‡é¢„æµ‹è¯¯å·®", f"{np.mean(errors[-30:]):.2f}")
col2.metric("é¢„æµ‹å‡†ç¡®æ€§", f"{np.mean(accuracy[-30:]):.2f}%")
col3.metric("æœ€æ–°å®é™…æ•°æ®", f"{hs300['close'].iloc[-1]:.2f}")

# æ˜¾ç¤ºå†å²é¢„æµ‹å‡†ç¡®æ€§
st.line_chart(pd.DataFrame({
    'å®é™…å€¼': actuals[-30:],
    'é¢„æµ‹å€¼': predictions[-30:]
}), use_container_width=True)

# å…è´£å£°æ˜
st.divider()
st.caption("å…è´£å£°æ˜ï¼šæœ¬é¢„æµ‹ä»…åŸºäºå†å²æ•°æ®æ¨¡å‹è®¡ç®—ï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚å¸‚åœºæœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚")
